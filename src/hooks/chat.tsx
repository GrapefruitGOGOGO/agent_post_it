import type { BubbleListProps } from 'ant-design-x-vue'
import { ref } from 'vue'
import OpenAI from 'openai'
import markdownit from 'markdown-it'
import { Space, Spin, Typography } from 'ant-design-vue'
import { tools } from './itemFunctions'
import type {
  ChatCompletionTool,
  ChatCompletionMessageParam,
  ChatCompletionToolMessageParam,
  ChatCompletionSystemMessageParam,
  ChatCompletionUserMessageParam,
  ChatCompletionAssistantMessageParam,
  ChatCompletionMessageToolCall,
} from 'openai/resources'
import { itemTools } from './itemFunctions'
import dayjs from 'dayjs'

/* è§£æmarkdown */
const md = markdownit({ html: true, breaks: true })

// æ¶ˆæ¯ç±»å‹å®šä¹‰
type MessageRole = 'user' | 'assistant' | 'system' | 'tool'

interface BaseMessage {
  key: number
  role: MessageRole
  content: string
}

interface UserMessage extends BaseMessage {
  role: 'user'
}

interface AssistantMessage extends BaseMessage {
  role: 'assistant'
  tool_calls?: ChatCompletionMessageToolCall[]
}

interface SystemMessage extends BaseMessage {
  role: 'system'
}

interface FunctionMessage extends BaseMessage {
  role: 'tool'
  name: string
  tool_call_id?: string
}

type Message = UserMessage | AssistantMessage | SystemMessage | FunctionMessage

type ShowMessage = Message & { loading?: boolean }

type MessageOptions = {
  name?: string
  tool_call_id?: string
  tool_calls?: ChatCompletionMessageToolCall[]
}

// UI é…ç½®
const loadingText = ref('æ™ºèƒ½ä½“è¿è¡Œä¸­...')
export const roles: BubbleListProps['roles'] = {
  assistant: {
    placement: 'start',
    header: <span style={{ fontSize: '12px', color: 'rgba(0, 0, 0, 0.3)' }}>ç‰©å“ä¾¿åˆ©è´´ï¼š</span>,
    avatar: {
      icon: (
        <img src="https://mdn.alipayobjects.com/huamei_iwk9zp/afts/img/A*s5sNRo5LjfQAAAAAAAAAAAAADgCCAQ/fmt.webp" />
      ),
      style: {
        background: 'none',
      },
    },
    typing: { step: 2, interval: 50 },
    messageRender: (content) => {
      return (
        <Typography>
          <div v-html={md.render(content)} />
        </Typography>
      )
    },
    loadingRender: () => (
      <Space>
        <Spin size="small" />
        {loadingText.value}
      </Space>
    ),
    variant: 'outlined',
    styles: {
      content: {
        fontSize: '16px',
        maxWidth: '90%',
      },
    },
  },
  user: {
    placement: 'end',
    color: '#165DFF',
    styles: {
      avatar: {
        display: 'none',
      },
      content: {
        backgroundColor: '#eff6ff',
        maxWidth: '90%',
        fontSize: '16px',
      },
    },
  },
}

// OpenAI å®¢æˆ·ç«¯
const openai = new OpenAI({
  baseURL: 'https://api.deepseek.com',
  apiKey: import.meta.env.VITE_OPENAI_API_KEY,
  dangerouslyAllowBrowser: true,
})

// æ¶ˆæ¯ç®¡ç†
class MessageManager {
  private messages: Message[] = []
  private readonly maxHistoryLength = 30

  // æ·»åŠ æ¶ˆæ¯
  addMessage(message: Message) {
    this.messages.push(message)
  }

  // è·å–æœ€è¿‘çš„æ¶ˆæ¯å†å²
  getRecentHistory(): Message[] {
    return this.messages.slice(-this.maxHistoryLength)
  }

  // è½¬æ¢ä¸º OpenAI æ¶ˆæ¯æ ¼å¼
  toOpenAIMessages(): ChatCompletionMessageParam[] {
    return this.getRecentHistory().map((msg) => {
      switch (msg.role) {
        case 'tool':
          return {
            role: 'tool',
            name: msg.name,
            content: msg.content,
            tool_call_id: msg.tool_call_id,
          } as ChatCompletionToolMessageParam
        case 'user':
          return {
            role: 'user',
            content: msg.content,
          } as ChatCompletionUserMessageParam
        case 'assistant':
          return {
            role: 'assistant',
            content: msg.content,
            tool_calls: msg.tool_calls,
          } as ChatCompletionAssistantMessageParam
        case 'system':
          return {
            role: 'system',
            content: msg.content,
          } as ChatCompletionSystemMessageParam
      }
    })
  }

  // æ¸…ç©ºæ¶ˆæ¯
  clear() {
    this.messages = []
  }
}

// çŠ¶æ€ç®¡ç†
const messageManager = new MessageManager() // æ¶ˆæ¯ç®¡ç†
export const messages = ref<ShowMessage[]>([]) // æ¶ˆæ¯åˆ—è¡¨
export const inputModel = ref('') // è¾“å…¥æ¡†å†…å®¹
export const isTyping = ref(false) // æ˜¯å¦æ­£åœ¨è¾“å…¥
export const isLoading = ref(false) // æ˜¯å¦æ­£åœ¨åŠ è½½

// åˆ›å»ºæ¶ˆæ¯
const createMessage = (
  role: MessageRole,
  content: string,
  options: MessageOptions = {},
): Message => {
  const baseMessage: BaseMessage = {
    key: Date.now(),
    role,
    content,
  }

  switch (role) {
    case 'tool':
      if (!options.name) throw new Error('Function messages must have a name')
      return {
        ...baseMessage,
        role: 'tool',
        name: options.name,
        tool_call_id: options.tool_call_id,
      } as FunctionMessage
    case 'assistant':
      return {
        ...baseMessage,
        role: 'assistant',
        tool_calls: options.tool_calls,
      } as AssistantMessage
    default:
      return baseMessage as Message
  }
}

// å¤„ç†å·¥å…·è°ƒç”¨
const handleToolCall = async (toolCall: ChatCompletionMessageToolCall, toolCallContent: string) => {
  try {
    console.log('ğŸš€ ~ handleToolCall ~ toolCall.function.name:', toolCall.function.name)
    const functionName = toolCall.function.name
    console.log('ğŸš€ ~ handleToolCall ~ functionName:', functionName)
    const args = JSON.parse(toolCallContent)

    const tool = itemTools[functionName as keyof typeof itemTools]
    if (!tool) {
      throw new Error(`æœªçŸ¥çš„å‡½æ•°: ${functionName}`)
    }
    loadingText.value = tool.beforeLoadingText
    const result = await tool.func(args)
    loadingText.value = tool.afterLoadingText

    return createMessage('tool', JSON.stringify(result), {
      name: toolCall.function.name,
      tool_call_id: toolCall.id,
    })
  } catch (error: unknown) {
    console.error('å·¥å…·è°ƒç”¨å¤±è´¥:', error)
    return createMessage(
      'tool',
      `å·¥å…·è°ƒç”¨å¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`,
      {
        name: toolCall.function.name,
        tool_call_id: toolCall.id,
      },
    )
  }
}

// è·å– AI å“åº”
const getResponse = async (isToolCall: boolean = false) => {
  const msgList: ChatCompletionMessageParam[] = [
    {
      role: 'system',
      content:
        'ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„æ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œå¹¶ç»™å‡ºå‹å¥½çš„å»ºè®®ã€‚\n' +
        'ä½ å¯ä»¥å¸®åŠ©ç”¨æˆ·ç®¡ç†å®¶åº­ç‰©å“ï¼ŒåŒ…æ‹¬æ·»åŠ ã€æŸ¥è¯¢ã€æ›´æ–°å’Œåˆ é™¤ç‰©å“ä¿¡æ¯ã€‚\n' +
        'ä½ åœ¨æ‰§è¡Œä»»åŠ¡æ—¶ï¼Œéœ€è¦ä»¥å½“å‰æ—¶é—´ä½œä¸ºå‚è€ƒï¼Œ' +
        'å½“å‰æ—¶é—´ï¼š' +
        dayjs().format('YYYY-MM-DD HH:mm:ss') +
        '\nè¯†åˆ«ç”¨æˆ·æ„å›¾æ—¶ï¼Œå½“ä½ æ— æ³•ç¡®è®¤æ˜¯å¦ç¬¦åˆä½ çš„å·¥ä½œå†…å®¹æ—¶ï¼Œå¯ä»¥å…ˆè°ƒç”¨åˆç†çš„toolsæ¥åˆ¤æ–­ï¼Œå¦‚æœç¡®è®¤ç”¨æˆ·æ„å›¾éç‰©å“ç®¡ç†ç›¸å…³ï¼Œè¯·ç®€è¦è¯´æ˜è‡ªå·±çš„èŒè´£å¹¶ç¤¼è²Œæ‹’ç»ï¼Œä¸è¦æä¾›ä»»ä½•é¢å¤–çš„å»ºè®®ã€‚',
    } as ChatCompletionSystemMessageParam,
    ...messageManager.toOpenAIMessages(),
  ]

  const response = await openai.chat.completions.create({
    model: 'deepseek-chat',
    messages: msgList,
    tools: tools as ChatCompletionTool[],
    tool_choice: 'auto',
    stream: true,
  })

  // åˆ›å»ºæ–°çš„åŠ©æ‰‹æ¶ˆæ¯
  const assistantMessage = createMessage('assistant', '')

  if (!isToolCall) {
    // æ–°å¢æ¶ˆæ¯
    messages.value.push({ ...assistantMessage, loading: true })
  }

  let currentToolCall: ChatCompletionMessageToolCall | null = null
  let toolCallContent = ''

  for await (const chunk of response) {
    const delta = chunk.choices[0]?.delta

    // å¤„ç†å·¥å…·è°ƒç”¨
    if (delta?.tool_calls) {
      const toolCall = delta.tool_calls[0]
      if (toolCall?.id) {
        currentToolCall = toolCall as ChatCompletionMessageToolCall
        toolCallContent = ''
        if (assistantMessage.role === 'assistant') {
          assistantMessage.tool_calls = delta.tool_calls.map((tc) => ({
            ...tc,
          })) as unknown as ChatCompletionMessageToolCall[]
        }
      }
      if (toolCall?.function?.arguments) {
        toolCallContent += toolCall.function.arguments
      }
    }

    // å¤„ç†æ¶ˆæ¯å†…å®¹
    if (delta?.content) {
      assistantMessage.content += delta.content
      // åŒæ­¥æ›´æ–°æ¶ˆæ¯
      const lastMessage = messages.value[messages.value.length - 1]
      if (lastMessage) {
        lastMessage.content = assistantMessage.content
        loadingText.value = 'æ™ºèƒ½ä½“è¿è¡Œä¸­...'
        lastMessage.loading = false
      }
    }
  }

  // æ·»åŠ æ¶ˆæ¯è®°å½•
  messageManager.addMessage(assistantMessage)

  if (currentToolCall && toolCallContent) {
    console.log('ğŸš€ ~ getResponse ~ currentToolCall:', currentToolCall)
    // å¤„ç†å·¥å…·è°ƒç”¨
    const functionMessage = await handleToolCall(currentToolCall, toolCallContent)
    // æ·»åŠ å·¥å…·è°ƒç”¨æ¶ˆæ¯è®°å½•
    messageManager.addMessage(functionMessage)
    // ç»§ç»­è·å– AI å“åº”
    await getResponse(true)
  }

  isTyping.value = false
  isLoading.value = false
}

// å¤„ç†ç”¨æˆ·æäº¤
export const handleSubmit = async () => {
  if (!inputModel.value.trim() || isLoading.value) return

  const userMessage = createMessage('user', inputModel.value)
  messageManager.addMessage(userMessage)
  messages.value.push({ ...userMessage })

  inputModel.value = ''
  isLoading.value = true
  isTyping.value = true

  await getResponse()
}
